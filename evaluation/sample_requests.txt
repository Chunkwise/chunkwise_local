------------------sample requests for MVP with S3 integration---------------

* "sample_document_medium" is the id of the S3 document to evaluate (i.e., document name without extension)

>> request body 1:
{
  "document_id": "sample_document_small",
  "query_generation_config": {
    "num_rounds": 1,
    "queries_per_corpus": 3,
  },
  "chunking_configs": [
    {
      "provider": "langchain",
      "chunker_type": "recursive",
      "chunk_size": 300,
      "chunk_overlap": 20
    }
  ]
}

>> response 1: 
{
  "embedding_model": "openai.text-embedding-3-large",
  "corpus_id": "sample_document_small",
  "document_s3_key": "documents/sample_document_small.txt",
  "queries_s3_key": "queries/sample_document_small/llm_queries_sample_document_small.csv",
  "queries_generated": true,
  "num_queries": 2,
  "chunkers_evaluated": [
    "langchain recursive"
  ],
  "results": [
    {
      "iou_mean": 0.2017241379310345,
      "recall_mean": 1.0,
      "precision_mean": 0.2017241379310345,
      "precision_omega_mean": 0.6003401360544218
    }
  ]
}

-----------------------
>> request body 2:

* This query uses the existing queries csv file, which was generated and stored
 in S3 in the previous request

{
  "document_id": "sample_document_small",
  "queries_id": "llm_queries_sample_document_small",
  "chunking_configs": [
    {
      "provider": "chonkie",
      "chunker_type": "token",
      "chunk_size": 400,
      "chunk_overlap": 20
    }
  ]
}

>> response 2: 
{
  "embedding_model": "openai.text-embedding-3-large",
  "corpus_id": "sample_document_small",
  "document_s3_key": "documents/sample_document_small.txt",
  "queries_s3_key": "queries/sample_document_small/llm_queries_sample_document_small.csv",
  "queries_generated": false,
  "num_queries": 2,
  "chunkers_evaluated": [
    "chonkie token"
  ],
  "results": [
    {
      "iou_mean": 0.19138495092693564,
      "recall_mean": 1.0,
      "precision_mean": 0.19138495092693564,
      "precision_omega_mean": 0.3206089743589744
    }
  ]
}

-----------------
>> request body 3 (using a different chunker):
{
  "document_id": "test_document",
  "query_generation_config": {
    "num_rounds": 1,
    "queries_per_corpus": 3
  },
  "chunking_configs": [
    {
      "provider": "chonkie",
      "chunker_type": "token",
      "chunk_size": 400,
      "chunk_overlap": 30
    }
  ]
}

>> response 3:
{
    "embedding_model": "openai.text-embedding-3-large",
    "corpus_id": "test_document",
    "document_s3_key": "documents/test_document.txt",
    "queries_s3_key": "queries/test_document/llm_queries_test_document.csv",
    "queries_generated": true,
    "num_queries": 3,
    "chunkers_evaluated": [
        "chonkie token"
    ],
    "results": [
        {
            "iou_mean": 0.18521525215252152,
            "recall_mean": 0.8313253012048193,
            "precision_mean": 0.18733333333333332,
            "precision_omega_mean": 0.23745487217185332
        }
    ]
}


-----------------------Legacy sample requests (local file storage)-----------------------

>> sample request body 1 (using sample_document_medium.txt + LLM query generation):
{
  "document_path": "data/sample_document_medium.txt",
  "chunking_configs": [
    {
      "provider": "langchain",
      "chunker_type": "langchain_token",
      "chunk_size": 512,
      "chunk_overlap": 0
    }
  ]
}

>> sample results 1 (48.73s - continous generation on existing csv, hence taking longer):
{
    "embedding_model": "text-embedding-3-large",
    "document_id": "sample_document_medium.txt",
    "document_path": "data/sample_document_medium.txt",
    "queries_path": "data/llm_queries_sample_document_medium.csv",
    "queries_generated": true,
    "num_queries": 8,
    "chunkers_evaluated": [
        "langchain_token"
    ],
    "results": [
        {
            "iou_mean": 0.030520086862803164,
            "recall_mean": 1.0,
            "precision_mean": 0.030520086862803164,
            "precision_omega_mean": 0.10372841587025362,
            "chunker_config": {
                "provider": "langchain",
                "chunker_type": "langchain_token",
                "chunk_size": 512,
                "chunk_overlap": 0,
                "encoding_name": "gpt2",
                "model_name": null,
                "allowed_special": [],
                "disallowed_special": "all"
            }
        }
    ]
}

------------------------------------------------

>> sample request body 2 (using sample_document_medium.txt + existing queries):
{
  "document_path": "data/sample_document_medium.txt",
  "queries_path": "data/llm_queries_sample_document_medium.csv",
  "chunking_configs": [
    {
      "chunker_type": "chonkie_token",
      "provider": "chonkie",
      "chunk_size": 400,
      "chunk_overlap": 20
    }
  ]
}

>> sample results 2 (2.17s):
{
    "embedding_model": "text-embedding-3-large",
    "document_id": "sample_document_medium.txt",
    "document_path": "data/sample_document_medium.txt",
    "queries_path": "data/llm_queries_sample_document_medium.csv",
    "queries_generated": false,
    "num_queries": null,
    "chunkers_evaluated": [
        "chonkie_token"
    ],
    "results": [
        {
            "iou_mean": 0.08565892115564278,
            "recall_mean": 0.8503097544492002,
            "precision_mean": 0.0934375,
            "precision_omega_mean": 0.30374950990117716,
            "chunker_config": {
                "provider": "chonkie",
                "tokenizer": "character",
                "chunker_type": "chonkie_token",
                "chunk_size": 400,
                "chunk_overlap": 20
            }
        }
    ]
}

------------------------------------------------

>> sample request body 3 (using sample_document_large.tx + existing queries):
{
  "document_path": "data/sample_document_large.txt",
  "queries_path": "data/llm_queries_sample_document_large.csv",
  "chunking_configs": [
    {
      "chunker_type": "langchain_recursive",
      "provider": "langchain",
      "chunk_size": 512,
      "chunk_overlap": 0
    }
  ]
}

>> sample results 3 (1857ms):
{
    "embedding_model": "text-embedding-3-large",
    "document_id": "sample_document_large.txt",
    "document_path": "data/sample_document_large.txt",
    "queries_path": "data/llm_queries_sample_document_large.csv",
    "queries_generated": false,
    "num_queries": null,
    "chunkers_evaluated": [
        "langchain_recursive"
    ],
    "results": [
        {
            "iou_mean": 0.06658228268349324,
            "recall_mean": 0.5855245753272069,
            "precision_mean": 0.06722162922271713,
            "precision_omega_mean": 0.4669151372307604,
            "chunker_config": {
                "provider": "langchain",
                "chunk_size": 512,
                "chunk_overlap": 0,
                "length_function": "len",
                "keep_separator": true,
                "add_start_index": false,
                "strip_whitespace": true,
                "chunker_type": "langchain_recursive",
                "separators": null,
                "is_separator_regex": false
            }
        }
    ]
}